{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\Logo_UCLL_ENG_RGB.png\" style=\"background-color:white;\" />\n",
    "\n",
    "# Data Analytics & Machine learning\n",
    "\n",
    "Lecturers: Aim√©e Lynn Backiel, Chidi Nweke, Daan Nijs\n",
    "\n",
    "Academic year 2023-2024\n",
    "\n",
    "## Lab 2: Introduction to the case and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. Recap last week\n",
    "2. Introduction to the case\n",
    "3. Data exploration using Pandas\n",
    "   1. Univariate analysis\n",
    "   2. Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of last lecture(s)\n",
    "\n",
    "#### Week 1\n",
    "\n",
    "1. We ensured we had a valid Python installation.\n",
    "2. We learnt what a virtual environment is:\n",
    "   * Isolated Python executable and packages.\n",
    "   * We created a virtual environment.\n",
    "3. Absolute path vs relative path recap.\n",
    "4. Recap of data structures in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Turing Travelogue, or as everyone calls her, Ada just started working part time at her parents travel agency. She has a keen understanding and interest of everything related to applied computer science ranging from server & system management to full stack software development. Through database foundations she already understands how to query data and programming 1 and 2 covered the essentials about the Python programming language. Recently she has just decided to start learning about data analytics & machine learning as well.\n",
    "\n",
    "She uses her skills to connect to the travel agency's database where she finds many, normalized, tables. Ada recalls what she learnt in database foundations and performs all the correct joins. Afterwards she saves the data in the `data/` folder.\n",
    "\n",
    "\n",
    "She finds the following dataset:\n",
    "\n",
    "| Column Name          | Description                                                                                       |\n",
    "| -------------------- | ------------------------------------------------------------------------------------------------- |\n",
    "| SalesID              | Unique identifier for each sale.                                                                  |\n",
    "| Age                  | Age of the traveler.                                                                              |\n",
    "| Country              | Country of origin of the traveler.                                                                |\n",
    "| Membership_Status    | Membership level of the traveler in the booking system; could be 'standard', 'silver', or 'gold'. |\n",
    "| Previous_Purchases   | Number of previous bookings made by the traveler.                                                 |\n",
    "| Destination          | Travel destination chosen by the traveler.                                                        |\n",
    "| Stay_length          | Duration of stay at the destination.                                                              |\n",
    "| Guests               | Number of guests traveling (including the primary traveler).                                             |\n",
    "| Travel_month         | Month in which the travel is scheduled.                                                           |\n",
    "| Months_before_travel | Number of months prior to travel that the booking was made.                                       |\n",
    "| Earlybird_discount   | Boolean flag indicating whether the traveler received an early bird discount.                     |\n",
    "| Package_Type         | Type of travel package chosen by the traveler.                                                    |\n",
    "| Cost                 | Calculated cost of the travel package.                                                            |\n",
    "| Margin | The cost (for the traveler) - what the travel agency pays. |\n",
    " | Additional_Services_Cost| The amount of additional services (towels, car rentals, room service, ...) that was bought during the trip. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping Ada explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal for the remainder of this lab is to explore the data. We will specifically take four columns:\n",
    "\n",
    "* Cost\n",
    "* age\n",
    "* stay length\n",
    "* Destination\n",
    "\n",
    "Our goal is to find interesting relationships between them.\n",
    "\n",
    "As was covered in the book and lecture there are to main data types in analytics: categorical and continuous data. This is a crucial first step in your analysis because it determines what methods make sense on your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal is primarily to find out what influences the cost of the stay.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pandas\n",
    "\n",
    "<center><img src=\"images\\pandas_logo.png\"  style=\"background-color:white;\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas stands for panel data, a type of dataset used in economics. Although this was the reason Pandas was invented, it is widely used in across analytics and one of Python's many \"killer apps\". Essentially, it's a package that makes Python unique compared to some of its competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before we start it is a good idea to check if you have pandas installed yet. You can do that with the following command in a notebook cell `!pip list`. Notice the exclamation mark (!), it allows you to run things in a code cell as it were a terminal. You can also open the terminal itself and write `pip list`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`pip list` shows you the full set of packages you have installed. If you are making this lab from Google colab Pandas will already be installed. You can double check this with `!pip list | grep pandas`. `|` is the pipe operator which gives the result of the preceding statement to `grep` which searches the text for Pandas. You can run this on unix-based operating systems as well. If you are on Windows you can run the command: `!pip list | findstr pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | findstr pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**‚ùó If you have a long list of packages and you are not working from google Colab that is likely an indication you're not working from a virtual environment. Follow the instructions that were listed in the beginning of the class, ask us or send us an e-mail.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're working locally and have followed the instructions Pandas will not be installed yet. You can do so by running `pip install pandas` in the terminal or in a code cell (including the exclamation mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install Pandas\n",
    "\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know that Pandas is a massive library with a lot of features. For the scope of this course you won't need a lot of it. We recommend you to look at the <a href=./Pandas_Cheat_Sheet.pdf>the cheat sheet</a> to discover what functionality Pandas has. We also recommend you to read the documentation of some of the functions we are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is typically imported as pd by convention. The package makes it incredibly easy to read and write data from different file formats. On top of that it comes with many operations that make working with data easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # by convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üíªüìäüí°<a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\"> `pd.read_csv` is used to read data from a filepath.</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset = pd.read_csv(\"data/lab_2_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì To be sure: did we use a relative or an absolute path?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things you typically do with a dataset is print out the first few rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üíªüìäüí° <a href=https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html>dataframe.head() prints out the first few lines of the dataframe.</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the columns is equally trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed we will take a subset of our dataset cost, age, stay length and destination. Doing so is similar to working with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset[\"stay_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get multiple columns at once we need to pass in a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"country\", \"stay_length\", \"age\", \"cost\"]\n",
    "travel_dataset_subset = travel_dataset[columns]\n",
    "travel_dataset_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermezzo: Series and Dataframes are mutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first important thing to notice about Pandas dataframe is that they are a combination of Pandas Series (columns).\n",
    "\n",
    "<center><img src=\"images\\df_vs_series.png\"  style=\"background-color:white;\"></center>\n",
    "\n",
    "**‚ùó Pandas Series and Dataframes are mutable. This can be a big source of frustration and unexpected behavior.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest way to make a dataframe is start from a list of dictionaries\n",
    "\n",
    "students = [{\"name\": \"Omar\", \"age\": 21}, {\"name\": \"Alisha\", \"age\":19}, {\"name\": \"Joost\", \"age\":18}]\n",
    "students_df = pd.DataFrame(students)\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(students_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(students_df[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names = students_df[\"name\"]\n",
    "student_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas complains about you doing this.\n",
    "student_names[1] = \"Katrien\"\n",
    "student_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to try something out an want to \"keep\" your original data\n",
    "students_copy = students_df.copy()\n",
    "student_names = students_copy[\"name\"]\n",
    "student_names[1] = \"Alisha\"\n",
    "students_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Pandas is warning us of this behavior with *\"A value is trying to be set on a copy of a slice from a DataFrame\"*. The documentation and error message aren't particularly helpful for beginners but the small example above demonstrates what they mean and why it's a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration: univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that short detour we now know that changing our subset `travel_dataset_subset` means we also change our original dataset. We will continue the exploration of our country, stay_length, age and cost variables.\n",
    "\n",
    "1. We will start with a univariate analysis, which means we will explore one (uni) variable (variate) at a time. \n",
    "2. Later on we will move to two (bi) variables (variate) analyses \n",
    "3. We round it up with methods that are able to do multivariate analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that \n",
    "\n",
    "1. **Categorical variables** represent categories or labels (e.g., colors, genders). \n",
    "2. **Numeric variables** represent quantities and can be ordered or measured (e.g., age, height). \n",
    "3. There is a special case called **Ordinal variables**, these are categories where there is a meaningful order (e.g., clothes sizes: small, medium and large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Which variables are categorical and which are numeric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Do you recall how we can \"summarize\" or describe numeric variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Carry this analysis out on the numeric variable(s).\n",
    "\n",
    "üíªüìäüí° TIP: the names of the functions are intuitive. For instance `dataframe[column].min()` gets the minimum of that column. It is equivalent to `select min(column) from dataframe` in SQL. Knowing SQL makes it easy to translate back and forth.\n",
    "\n",
    "üíªüìäüí° TIP: become good friends with the <a href=./Pandas_Cheat_Sheet.pdf>the cheat sheet</a> and the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Doing this one by one gets quite tedious. Is there any other way listed on the cheat sheet to do this for all variables at once?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Carry this analysis out on the categorical variable(s).\n",
    "\n",
    "üíªüìäüí° TIP: `dataframe[column].value_counts()` is a very powerful method. It is equivalent to `select column, count(column) from dataframe group by column`. If you forget `value_counts()` exists you can get there using your SQL knowledge. `dataframe.groupby(\"column\").count()` also gets you very close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration: bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will always also look at the combinations of variables and see if those have interesting insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What pairs of variables do you think are interesting to look at?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What methods can you use to do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Carry out these analyses\n",
    "\n",
    "üíªüìäüí° TIP: Things like  `dataframe[[\"column1\", \"column2\"]].groupby(\"column1\").mean()` are valid Pandas. In SQL this would be `select column1, mean(column2) from dataframe group by column 1` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That rounds up today's session. In the next session we will cover plotting in Python using Matplotlib and Seaborn. Right now all of your data analysis has been tables but plots are a lot more ergonomic to present your results in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
