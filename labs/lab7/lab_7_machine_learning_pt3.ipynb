{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\Logo_UCLL_ENG_RGB.png\" style=\"background-color:white;\" />\n",
    "\n",
    "# Data Analytics & Machine learning\n",
    "\n",
    "Lecturers: Aim√©e Lynn Backiel, Chidi Nweke, Daan Nijs\n",
    "\n",
    "Academic year 2023-2024\n",
    "\n",
    "## Lab 7: Machine learning, part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. Recap of previous weeks\n",
    "2. Automating machine learning pipelines with sci-kit learn\n",
    "3. Model evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of last lab was on using sci-kit learn's tools to made models. On top of that we saw different important performance metrics for regression and how to use them in sci-kit learn. Our overarching goal remains the same: we want to try out various approaches and select the best one afterwards. This lecture we will continue that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of last lecture(s)\n",
    "\n",
    "#### Lab 1\n",
    "\n",
    "1. We ensured we had a valid Python installation.\n",
    "2. We learnt what a virtual environment is:\n",
    "   * Isolated Python executable and packages.\n",
    "   * We created a virtual environment.\n",
    "3. Absolute path vs relative path recap.\n",
    "4. Recap of data structures in Python\n",
    "\n",
    "#### Lab 2\n",
    "1. Installed Pandas\n",
    "2. Learnt how to read data\n",
    "3. Learnt how to calculate mean, mode, median etc.\n",
    "4. Basic exploration of the 4 variables\n",
    "\n",
    "#### Lab 3\n",
    "1. Wrapped up computing summary statistics (mean, median, mode, ...)\n",
    "2. Learnt how to deal with outliers \n",
    "3. Focused on exploration of dat\n",
    "\n",
    "#### Lab 4\n",
    "1. Univariate data visualization using Matplotlib\n",
    "   1. Figures and axes\n",
    "   2. Histograms\n",
    "   3. Box plots\n",
    "   4. Bar charts\n",
    "2. Multivariate data visualization using Seaborn\n",
    "   1. Scatter plots\n",
    "   2. Small multiples\n",
    "   3. Color coding\n",
    "\n",
    "#### Lab 5\n",
    "1. Intro to machine learning using scikit-learn\n",
    "   1. Preprocessing\n",
    "      1. One Hot encoding\n",
    "      2. Scaling\n",
    "      3. Outliers\n",
    "   2. Regression\n",
    "\n",
    "#### Lab 6\n",
    "1. Preprocessing with scikit-learn\n",
    "   1. ColumnTransformer: Apply a transformation to specific columns.\n",
    "   2. Pipeline: Do several transformations after each other\n",
    "2. Evaluation:\n",
    "   1. Why the mean of the error is a bad idea\n",
    "   2. Mean absolute error\n",
    "   3. Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Turing Travelogue, or as everyone calls her, Ada just started working part time at her parents travel agency. She has a keen understanding and interest of everything related to applied computer science ranging from server & system management to full stack software development. Through database foundations she already understands how to query data and programming 1 and 2 covered the essentials about the Python programming language. Recently she has just decided to start learning about data analytics & machine learning as well.\n",
    "\n",
    "She uses her skills to connect to the travel agency's database where she finds many, normalized, tables. Ada recalls what she learnt in database foundations and performs all the correct joins. Afterwards she saves the data in the `data/` folder.\n",
    "\n",
    "\n",
    "She finds the following dataset:\n",
    "\n",
    "| Column Name          | Description                                                                                       |\n",
    "| -------------------- | ------------------------------------------------------------------------------------------------- |\n",
    "| SalesID              | Unique identifier for each sale.                                                                  |\n",
    "| Age                  | Age of the traveler.                                                                              |\n",
    "| Country              | Country of origin of the traveler.                                                                |\n",
    "| Membership_Status    | Membership level of the traveler in the booking system; could be 'standard', 'silver', or 'gold'. |\n",
    "| Previous_Purchases   | Number of previous bookings made by the traveler.                                                 |\n",
    "| Destination          | Travel destination chosen by the traveler.                                                        |\n",
    "| Stay_length          | Duration of stay at the destination.                                                              |\n",
    "| Guests               | Number of guests traveling (including the primary traveler).                                             |\n",
    "| Travel_month         | Month in which the travel is scheduled.                                                           |\n",
    "| Months_before_travel | Number of months prior to travel that the booking was made.                                       |\n",
    "| Earlybird_discount   | Boolean flag indicating whether the traveler received an early bird discount.                     |\n",
    "| Package_Type         | Type of travel package chosen by the traveler.                                                    |\n",
    "| Cost                 | Calculated cost of the travel package.                                                            |\n",
    "| Margin | The cost (for the traveler) - what the travel agency pays. |\n",
    " | Additional_Services_Cost| The amount of additional services (towels, car rentals, room service, ...) that was bought during the trip. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our challenge\n",
    "\n",
    "Before getting into harder use cases we will start off by predicting the cost of a given stay. Right now Ada's parents do this manually automating this task would already be a big help to their business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://www.datascience-pm.com/wp-content/uploads/2021/02/CRISP-DM.png\" style=\"background-color:white;width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning with sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" style=\"background-color:white;width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What have we done so far of the image below? What stages have we completed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue from last lecture. We covered two cornerstones of sklearn namely:\n",
    "\n",
    "1. `make_column_transformer`, this allows you to specify preprocessing you want to apply for different columns. E.g., scaling for numeric columns and one hot encoding for categorical.\n",
    "2. `make_pipeline`, this allows you to compose several steps. So our first step could be preprocessing and the second our ML model. A pipeline is an end-to-end object that lets you go from raw data to a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model evaluation using sci-kit learn (Summary of last lab's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # by convention\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import numpy  as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_dataset = pd.read_csv(\"data/lab_7_dataset.csv\")\n",
    "X = travel_dataset.drop(columns=\"cost\") \n",
    "y = travel_dataset[\"cost\"] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"package_Type\", \"destination\", \"country\"]\n",
    "numeric_columns = [\"guests\", \"age\", \"stay_length\"]\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (StandardScaler(), numeric_columns),\n",
    "    (OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_pipe = make_pipeline(preprocessing, LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Answer to previous lab's question (New material as from here)\n",
    " \n",
    " ‚ùì Use the pipeline approach discussed above and the mean_absolute_error and mean_squared_error for the following models: RandomForestRegressor, HistGradientBoostingRegressor, DecisionTreeRegressor and LinearRegression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the answer to last session's final question. It also serves as a summary of all the new approaches covered there:\n",
    "\n",
    "1. `model_name_pair` contains a list of tuples with different models inside. We loop over them and try them one-by-one.\n",
    "2. `make_pipeline` takes the preprocessing (scaling numeric columns and one hot encoding categorical columns) and immediately places the model behind it. both `.fit` and `.predict` will now both apply the preprocessing and the model in one go.\n",
    "3. Predictions are make on the training and the test set.\n",
    "4. The results are evaluated by means of the MAE and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° for those interested: `n_jobs = 7` instructs the model to use 7 CPU cores while training. This is a considerable speed-up for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_pair = [(\"random_forest\", RandomForestRegressor(n_jobs=7)), (\"gradient boosting\", HistGradientBoostingRegressor()), (\"decision tree\", DecisionTreeRegressor()), (\"linear regression\", LinearRegression()) ]\n",
    "results = []\n",
    "for pair in model_name_pair:\n",
    "    name, model = pair\n",
    "    print(f\"STARTING {name}\")\n",
    "    pipe = make_pipeline(preprocessing, model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    predictions_train = pipe.predict(X_train)\n",
    "    predictions_test = pipe.predict(X_test)\n",
    "    print(\"-\"*20)\n",
    "    print(f\"The MAE on the training set is {mean_absolute_error(y_train, predictions_train)} and on the test set it is {mean_absolute_error(y_test, predictions_test)}\")\n",
    "    print(f\"The mse on the training set is {mean_squared_error(y_train, predictions_train, squared=False)} and on the test set it is {mean_squared_error(y_test, predictions_test, squared=False)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Comment on the behavior of the models. Are they overfitting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best model: feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in the previous session we made a number of observations:\n",
    "\n",
    "* If you're visiting the same country as you're from the destination seemed to be cheaper\n",
    "* If you're traveling in approximately the same continent it's also cheaper\n",
    "* There might be the case between age and month.\n",
    "* Maybe we should look at age in groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_to_country = {\n",
    "        \"New York\": \"USA\",\n",
    "        \"Rome\": \"Italy\",\n",
    "        \"Paris\": \"France\",\n",
    "        \"Tokyo\": \"Japan\",\n",
    "        \"Cairo\": \"Egypt\",\n",
    "        \"Sydney\": \"Australia\",\n",
    "        \"Rio\": \"Brazil\",\n",
    "        \"Cape Town\": \"South Africa\",\n",
    "    }\n",
    "country_to_continent = {\n",
    "        \"USA\": \"America\",\n",
    "        \"UK\": \"EMEA\",\n",
    "        \"France\": \"EMEA\",\n",
    "        \"Canada\": \"America\",\n",
    "        \"Australia\": \"Asia\",\n",
    "        \"Germany\": \"EMEA\",\n",
    "        \"Spain\": \"EMEA\",\n",
    "        \"Italy\": \"EMEA\",\n",
    "    }\n",
    "destination_to_continent = {\n",
    "        \"New York\": \"America\",\n",
    "        \"Rome\": \"EMEA\",\n",
    "        \"Paris\": \"EMEA\",\n",
    "        \"Tokyo\": \"Asia\",\n",
    "        \"Cairo\": \"EMEA\",\n",
    "        \"Sydney\": \"Asia\",\n",
    "        \"Rio\": \"America\",\n",
    "        \"Cape Town\": \"Africa\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Use Pandas to make a variables to indicate if they traveled to the same country and then the same continent. \n",
    "\n",
    "##### HINT1: Look at [the map method for Pandas series](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html). \n",
    "\n",
    "##### HINT2: Remember, a series is simply a column so , `df[column]` gives you a series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to add these variables there is some friction. They don't fit into our sci-kit learn `Pipeline` workflow nicely. We could add them to our entire dataset before splitting. Adding variables to the entire dataset is not risk-free. Doing so may lead to the methodological error we spoke about previously **data leakage**. In the scope of this course it's fine to use this approach to *add* variables. We'll briefly show you the more principled way, but you don't need to know this for the exam. It involves creating a custom `Transformer` which we can then compose in our pipeline as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class CountryMapping(TransformerMixin, BaseEstimator):\n",
    "    country_to_continent: dict[str, str]\n",
    "    destination_to_country: dict[str, str]\n",
    "    destination_to_continent: dict[str, str]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        _X = X.copy() # so we don't change our input data frame\n",
    "        _X['country_match'] = _X['country'] == _X['destination'].map(self.destination_to_country)\n",
    "        _X['continent_match'] = _X['country'].map(self.country_to_continent) == _X['destination'].map(self.destination_to_continent)\n",
    "        return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map = CountryMapping(country_to_continent, destination_to_country, destination_to_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can later add this as a new preprocessing step to our column transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We briefly make a transformer called `do_nothing_to`. The semantics aren't important as this is something you will rarely need in practice and definitely not on the exam. All it does is make an anonymous function (a function without a name) that takes an input and returns that as output so it effectively does nothing. We make it a transformer by giving it to `FunctionTransformer`.\n",
    "\n",
    "üí° The reason why this is necessary is that our columns transformer is configured to drop all unused columns. We need to \"use\" it for a column to stay in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FunctionTransformer\n",
    "\n",
    "\n",
    "do_nothing_to = FunctionTransformer(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_country = make_column_transformer(\n",
    "    (StandardScaler(), numeric_columns),\n",
    "    (OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    (do_nothing_to,  [\"country_match\", \"continent_match\"]),\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.jmp.com/en_se/statistics-knowledge-portal/what-is-multiple-regression/mlr-with-interactions/_jcr_content/par/styledcontainer_2069/par/lightbox_3be9/lightboxImage.img.png/1548351208495.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider an alternative approach to the problem above using interaction terms. Interaction terms are created by multiplying two variables together, effectively creating a new variable. This is a mathematical way of capturing the 'AND' condition in our data. For example, after one-hot encoding categorical variables like 'Country' and 'Destination', we can generate interaction terms to explore the combined effect of these two features.\n",
    "\n",
    "Suppose we have 'New York', 'Rome', 'Tokyo', and 'Cairo' as categories for 'City' and 'USA', 'Italy', 'Japan', and 'Egypt' for 'Country'. If we create interaction terms for 'City' and 'Country', we end up with additional columns such as 'New York x USA', 'Rome x Italy', and so on. Each of these new columns will have a value of 1 only if both contributing variables (e.g., 'City' is 'New York' AND 'Country' is 'USA') are 1; otherwise, the value will be 0. This new variable thus answers the question: \"Is the traveler from X city AND going to Y country?\"\n",
    "\n",
    "By including interaction terms, we allow our model to consider the combined influence of two variables, which can be particularly insightful when the effect of one variable on the outcome depends on the level of another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, interaction effects between variables can be encoded using the `PolynomialFeatures` transformer. Interaction effects are valuable in a model when the relationship between two features can affect the outcome in a way that is not simply additive.\n",
    "\n",
    "For example, consider two binary features, A and B. Individually, they might have a certain effect on the target variable Y. However, when both A and B occur together (i.e., A=1 and B=1), their combined effect on Y could be different from the sum of their individual effects. This is where interaction terms come into play.\n",
    "\n",
    "The PolynomialFeatures transformer can not only generate polynomial features, which are features raised to a power (like $x^{2}$ or $x^{3}$), but also interaction features, which are products of features (like $x_{1} * x_{2}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: polynomial is called \"veelterm\" in Dutch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start off by generating interactions between all our numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "\n",
    "numeric_preprocessing = make_pipeline(StandardScaler(), poly)\n",
    "\n",
    "preprocessing_interactions = make_column_transformer(\n",
    "    (numeric_preprocessing, numeric_columns),\n",
    "    (do_nothing_to,  [\"country_match\", \"continent_match\"]),\n",
    "    (OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2000/1*LGTAObYYj2-fdBMFLz30rw.jpeg\" style=\"width:50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning is a technique that involves segmenting a continuous variable into several intervals, or 'bins'. Similar to the way we categorize data when creating histograms, binning transforms a continuous variable into an ordered categorical variable. One hot encoding these bins allows us to introduce non-linear effects into our linear models, which ordinarily would interpret the data as having a constant slope.\n",
    "\n",
    "Take temperature as an example: people generally enjoy mild increases in weather warmth, but there's a threshold beyond which higher temperatures become unpleasant. Binning would let us model this non-linear relationship. Instead of treating temperature as a single continuous predictor with a constant effect, we could divide temperatures into ranges (e.g., 0-10¬∞C, 10-20¬∞C, 20-30¬∞C, etc.) and treat each range as a separate category. By one hot encoding these categories, we enable our model to capture the varying effects of different temperature ranges on people's comfort levels. This approach can reveal more complex patterns in how the predictor variable (in this case, temperature) influences the outcome variable (such as people's reported happiness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "preprocessing_bins = make_column_transformer(\n",
    "    (StandardScaler(), numeric_columns),\n",
    "    (KBinsDiscretizer(),  [\"age\"]),\n",
    "    (do_nothing_to,  [\"country_match\", \"continent_match\"]),\n",
    "    (OneHotEncoder(), cat_columns),\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "preprocessing_bins_interactions = make_column_transformer(\n",
    "    (numeric_preprocessing, numeric_columns),\n",
    "    (KBinsDiscretizer(), [\"age\"]),\n",
    "    (do_nothing_to,  [\"country_match\", \"continent_match\"]),\n",
    "    (OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best model: cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we explore various models and preprocessing techniques, we encounter a dilemma: how do we identify the best model without biasing our selection? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What is the weakness of the train-test split approach? Think about this before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Think about a solution for this before we continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's how it works: We divide our training set into smaller sections, say 20% chunks. We train our model on 80% of the data, then validate it on the remaining 20%. We repeat this process five times, each time with a different 20% held out for validation. This technique, known as k-fold cross-validation (with k being the number of chunks or 'folds' we create), allows each model a fair shot at proving itself across the entirety of our data.\n",
    "\n",
    "By averaging the performance across these folds, we obtain a more reliable measure of a model's quality. This thorough approach increases our confidence that we're selecting the best model, not by chance, but by consistent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" style=\"background-color:white\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Sanity check: if we do K-fold cross validation, how many models have we trained. Answer for 2-fold, 3-fold, 5-fold and K-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì What is the downside of K-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, sci-kit learn makes it easy to do cross validation. \n",
    "\n",
    "We supply `cross_val_score` with 3 mandatory parameters:\n",
    "\n",
    "* The machine learning model\n",
    "* The `X_train`\n",
    "* `X_test`\n",
    "  \n",
    "Additionally you can use `cv` to specify how many folds and you can pick a `score` parameter, which is the result that will be reported to you as the performance on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_reg_cv_results = cross_val_score(lin_reg_pipe, X_train, y_train, cv=5, scoring= \"neg_root_mean_squared_error\")\n",
    "lin_reg_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lin_reg_cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_pipe = make_pipeline(numeric_preprocessing, DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_cv_results = cross_val_score(decision_tree_pipe, X_train, y_train, cv=5, scoring= \"neg_root_mean_squared_error\")\n",
    "decision_tree_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(decision_tree_cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Interpret these values. Which model performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Contrast the performance seen in the beginning of this notebook of these two models. Think about overfitting and so on. (Key Insight!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Your turn: experiment with different models and setups. Try out the new pre processing pipelines with a variety of machine learning models and cross validation. Feel free to reuse some of the evaluation code of the beginning of the lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_country \n",
    "preprocessing_interactions\n",
    "preprocessing_bins\n",
    "preprocessing_bins_interactions;\n",
    "\n",
    "# Your pipeline should look like this: pipe = make_pipeline(country_map, prep, model)\n",
    "# Deviations from this will likely cause an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_pair = [(\"random_forest\", RandomForestRegressor(n_jobs=7)), (\"gradient boosting\", HistGradientBoostingRegressor()), (\"decision tree\", DecisionTreeRegressor()), (\"linear regression\", LinearRegression()) ]\n",
    "preprocessing = [(\"same country and continent\", preprocessing_country), (\"interactions\", preprocessing_interactions), (\"bins\", preprocessing_bins), (\"bins and interactions\", preprocessing_bins_interactions) ]\n",
    "results = []\n",
    "for pair in model_name_pair:\n",
    "    name, model = pair\n",
    "    for prep_name, prep in preprocessing:\n",
    "        print(f\"STARTING {name} with preprocessing = {prep_name}\")\n",
    "        pipe = make_pipeline(country_map, prep, model)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        predictions_train = pipe.predict(X_train)\n",
    "        predictions_test = pipe.predict(X_test)\n",
    "        print(\"-\"*20)\n",
    "        print(f\"The MAE on the training set is {mean_absolute_error(y_train, predictions_train)} and on the test set it is {mean_absolute_error(y_test, predictions_test)}\")\n",
    "        print(f\"The mse on the training set is {mean_squared_error(y_train, predictions_train, squared=False)} and on the test set it is {mean_squared_error(y_test, predictions_test, squared=False)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì Is this an improvement over before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best model: can we do more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already tried different methods like creating new features and grouping data. These methods have sometimes made our models better. But, there's more we can do.\n",
    "\n",
    "Machine learning is a process that goes in circles, as shown in the CRISP-DM image. Once we build models, there are ways to look more closely at how they work.\n",
    "\n",
    "1. Comparing Predicted and Actual Results\n",
    "   \n",
    "The first step we did was to compare what our model predicted with the real results. This helps us see where the model does well and where it needs more work. It also shows anomalies, for instance certain models were predicting negative costs which should not be possible.\n",
    "\n",
    "2. Looking at Residuals\n",
    "   \n",
    "Here, we look at the errors - the difference between the real values (y_true) and what the model predicted (y_pred). We do this for each input in our model. The main idea is to look for patterns in these errors. For example, if we make charts showing errors for each country and notice that errors are bigger for certain countries, it tells us that we might need to improve our features. This is like doing analysis on the results of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters and hyperparameters (only theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do is called **hyperparameter tuning**. Hyperparameters are simply the \"settings\" of the machine learning model. Parameters are what it uses to make predictions. So for linear regression the parameters are the coefficients and for decision trees these are the splits it is making. \n",
    "\n",
    "Most machine learning models have hyperparameters (settings) as well. Typically they are used to decrease the complexity of the model. For a decision tree a hyperparameter is for instance the amount of splits it is allowed to make. For Random Forest and Gradient boosting the amount of trees it uses are a hyperparameter. For linear regression the regularization constant (punishment if the coefficients get large) is also a hyperparameter.**Hyperparameters help us combat overfitting.**\n",
    "\n",
    "\n",
    "Typically complex models have many different hyperparameters you can tune. We encourage you to look at the number of hyperparameters for the models we have used so far to get an idea:\n",
    "\n",
    "* [Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "* [Gradient boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html)\n",
    "* [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "* [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "\n",
    "Some models are very sensitive to their choice of hyperparameters. With their defaults they typically overfit, this is the case for random forest and decision trees (see above).\n",
    "\n",
    "To identify the best hyperparameters, techniques like grid search and random search are used. Grid search exhaustively explores all possible combinations of hyperparameters, offering a thorough but computationally intensive approach. Random search, on the other hand, samples a predetermined number of combinations randomly, providing a quicker but slightly less focused alternative.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/publication/341691661/figure/fig2/AS:896464364507139@1590745168758/Comparison-between-a-grid-search-and-b-random-search-for-hyper-parameter-tuning-The.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ‚ùì hyperparameters can be sensitive to specific parts of the data. We don't want hyperparameters that do well on one specific part of the data. What can we do to make sure we select hyperparameters that work well for the entire dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The key question is if manually doing grid search or random search is worth it.** The answer, as usual, is it depends.\n",
    "\n",
    "Counter-arguments: \n",
    "\n",
    "1. Linear regression in sci-kit learn automatically performs hyperparameter tuning:\n",
    "\n",
    "* [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "* [ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html)\n",
    "   \n",
    "Their names come from the specific regularization they perform, covering that is out of scope for this course.\n",
    "\n",
    "The CV stands for \"cross validation\". These models perform hyperparameter tuning with cross validation by default. For linear regression this is fine as this is a very inexpensive model to train.\n",
    "\n",
    "2. It is very time consuming.\n",
    "3. The difference can be negligible. You also don't know ahead of time if it will matter.\n",
    "4. It requires you to somewhat know the internal details of the models.\n",
    "5. Gradient boosting is extremely powerful with the default settings, it may not even require tuning.\n",
    "\n",
    "\n",
    "Arguments for:\n",
    "\n",
    "1. In some cases a 1 % difference absolutely makes a difference.\n",
    "\n",
    "This is related to point 3. Even if the difference is negligible at a certain scale a 1 % increase matters. For instance, if you have a ML model to predict how much food will be thrown out for a small grocery store a difference of 1 % does not really matter. If this is on the scale of the entire franchise then it is a worthwhile investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the complex image we began with, after our lab today, the process should be clearer:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" style=\"background-color:white;width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. You start by dividing your dataset into two parts: training and test data.\n",
    "2. The training data is then used for cross-validation. This technique is a reliable way to assess model performance and can be paired with hyperparameter tuning, although that's not mandatory.\n",
    "3. Choose the model or models that perform best in the cross-validation phase.\n",
    "4. These top models are then trained with the entire set of training data.\n",
    "5. finally, we test these models on the test data. The results from this step give us our final evaluation metrics.\n",
    "\n",
    "\n",
    "Remember, this method, aside from the optional step of hyperparameter tuning, is crucial for your exam. Evaluating and training on the same data is a practice we want to avoid because it can lead to overfitting, which is why we test our models on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
